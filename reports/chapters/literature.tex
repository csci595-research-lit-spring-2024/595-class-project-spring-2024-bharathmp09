\chapter{Literature Review}
\label{ch:lit_rev} %Label of the chapter lit rev. The key ``ch:lit_rev'' can be used with command \ref{ch:lit_rev} to refer this Chapter.


This section explores the existing existing body of knowledge surrounding the Comparative Analysis of Denoising Autoencoder (DAE) and Convolutional Neural Networks (CNN) for MNIST Classification. Recent advancements in deep machine learning have significantly improved feature learning in image processing tasks, particularly in image classification, making it imperative to explore and understand the capabilities and limitations of different models. Notably, Convolutional Neural Networks (CNNs) have emerged as powerful tools, showcasing superior performance in image classification tasks. However, the inherent challenge of noise in real-world data poses a significant constraint on the performance of deep neural networks, prompting the exploration of denoising techniques. The literature review will examine prior studies focusing on image denoising methods, including traditional approaches and those leveraging deep learning, with a specific emphasis on Denoising Autoencoders. Understanding the existing landscape is crucial for contextualizing the current research and identifying gaps that the Comparative Analysis seeks to address.

\section{Review of state-of-the-art}
The \citep{8078730} explores the application of deep learning, specifically Convolutional Neural Networks (CNNs), in image classification. The authors discuss various models commonly used in deep learning, such as Auto Encoder, sparse coding, Restricted Boltzmann Machine, Deep Belief Networks, and CNNs. They emphasize the effectiveness of CNNs in image classification, particularly showcasing their high performance. The study involves building a simple CNN for image classification, with experiments conducted on benchmark datasets like minist and cifar-10. The authors delve into the fundamental components of CNNs, including Convolutional layers, pooling layers, and fully-connected layers. The study focuses on learning rate strategies and optimization algorithms for solving optimal parameters in image classification. Different strategies are compared, demonstrating the impact on recognition rates during training and testing. 
The experimental results and 

The \citep{bajaj2020autoencoders} proposes an efficient image denoising technique using autoencoders based on deep learning models. The motivation behind image denoising is to eliminate noise from images, which can be caused by various factors such as defects in camera sensors, transmission in noisy channels, or faulty memory locations in hardware. The proposed model utilizes autoencoders, a type of artificial neural network, for image denoising. Autoencoders learn noise patterns from training images and attempt to eliminate noise from novel images. The proposed network architecture consists of convolutional denoising autoencoder (CDA) blocks, each containing internal layers like convolution, pooling, deconvolution, and upsampling. Skip connections are employed to enhance the model's ability to capture finer image details and facilitate backpropagation during training. The paper discusses related work, highlighting methods such as non-local means, Block Matching and 3D Matching (BM3D), and denoising autoencoders. STL-10 dataset for training and the SET5 standard image dataset for testing. Performance metrics, such as Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM), are used to evaluate the proposed model's effectiveness in comparison to baseline models. The results show that the proposed model outperforms Convolutional Denoising Deep Neural Network (CDDNN) and Residual Encoder Decoder with 30 layers (RED30) in terms of PSNR, indicating superior denoising capabilities.


% A possible section of you chapter
\section{Critique of the review} % Use this section title or choose a betterone
Describe your main findings and evaluation of the literature. ~\\

% Pleae use this section
\section{Summary} 
Write a summary of this chapter~\\
